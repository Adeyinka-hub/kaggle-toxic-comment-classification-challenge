Build model to detect different types of toxicity like threats, obscenity, insults, and identity-based hate.
